{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYp0bXOFK-hP"
   },
   "source": [
    "# Машинное обучение, ФКН ВШЭ\n",
    "\n",
    "## Практическое задание 8. Метод опорных векторов и аппроксимация ядер\n",
    "\n",
    "### Общая информация\n",
    "\n",
    "Дата выдачи: 28.01.2022\n",
    "\n",
    "Мягкий дедлайн: 23:59MSK 14.02.2022\n",
    "\n",
    "Жесткий дедлайн: 23:59MSK 17.02.2022\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимальная оценка за работу (без учёта бонусов) — 10 баллов.\n",
    "\n",
    "Сдавать задание после указанного жёсткого срока сдачи нельзя. При выставлении неполного балла за задание в связи с наличием ошибок на усмотрение проверяющего предусмотрена возможность исправить работу на указанных в ответном письме условиях.\n",
    "\n",
    "Задание выполняется самостоятельно. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий (или его часть) в открытом источнике, необходимо указать ссылку на этот источник в отдельном блоке в конце вашей работы (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, необходима ссылка на источник).\n",
    "\n",
    "Неэффективная реализация кода может негативно отразиться на оценке.\n",
    "\n",
    "### Формат сдачи\n",
    "Задания сдаются через систему anytask. Посылка должна содержать:\n",
    "* Ноутбук homework-practice-08-random-features-Username.ipynb\n",
    "\n",
    "Username — ваша фамилия и имя на латинице именно в таком порядке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vY8vT0W_K-hR"
   },
   "source": [
    "### О задании\n",
    "\n",
    "На занятиях мы подробно обсуждали метод опорных векторов (SVM). В базовой версии в нём нет чего-то особенного — мы всего лишь используем специальную функцию потерь, которая не требует устремлять отступы к бесконечности; ей достаточно, чтобы отступы были не меньше +1. Затем мы узнали, что SVM можно переписать в двойственном виде, который, позволяет заменить скалярные произведения объектов на ядра. Это будет соответствовать построению модели в новом пространстве более высокой размерности, координаты которого представляют собой нелинейные модификации исходных признаков.\n",
    "\n",
    "Ядровой SVM, к сожалению, довольно затратен по памяти (нужно хранить матрицу Грама размера $d \\times d$) и по времени (нужно решать задачу условной оптимизации с квадратичной функцией, а это не очень быстро). Мы обсуждали, что есть способы посчитать новые признаки $\\tilde \\varphi(x)$ на основе исходных так, что скалярные произведения этих новых $\\langle \\tilde \\varphi(x), \\tilde \\varphi(z) \\rangle$ приближают ядро $K(x, z)$.\n",
    "\n",
    "Мы будем исследовать аппроксимации методом Random Fourier Features (RFF, также в литературе встречается название Random Kitchen Sinks) для гауссовых ядер. Будем использовать формулы, которые немного отличаются от того, что было на лекциях (мы добавим сдвиги внутрь тригонометрических функций и будем использовать только косинусы, потому что с нужным сдвигом косинус превратится в синус):\n",
    "$$\\tilde \\varphi(x) = (\n",
    "\\cos (w_1^T x + b_1),\n",
    "\\dots,\n",
    "\\cos (w_n^T x + b_n)\n",
    "),$$\n",
    "где $w_j \\sim \\mathcal{N}(0, 1/\\sigma^2)$, $b_j \\sim U[-\\pi, \\pi]$.\n",
    "\n",
    "На новых признаках $\\tilde \\varphi(x)$ мы будем строить любую линейную модель.\n",
    "\n",
    "Можно считать, что это некоторая новая парадигма построения сложных моделей. Можно направленно искать сложные нелинейные закономерности в данных с помощью градиентного бустинга или нейронных сетей, а можно просто нагенерировать большое количество случайных нелинейных признаков и надеяться, что быстрая и простая модель (то есть линейная) сможет показать на них хорошее качество. В этом задании мы изучим, насколько работоспособна такая идея.\n",
    "\n",
    "### Алгоритм\n",
    "\n",
    "Вам потребуется реализовать следующий алгоритм:\n",
    "1. Понизить размерность выборки до new_dim с помощью метода главных компонент.\n",
    "2. Для полученной выборки оценить гиперпараметр $\\sigma^2$ с помощью эвристики (рекомендуем считать медиану не по всем парам объектов, а по случайному подмножеству из где-то миллиона пар объектов): $$\\sigma^2 = \\text{median}_{i, j = 1, \\dots, \\ell, i \\neq j} \\left\\{\\sum_{k = 1}^{d} (x_{ik} - x_{jk})^2 \\right\\}$$\n",
    "3. Сгенерировать n_features наборов весов $w_j$ и сдвигов $b_j$.\n",
    "4. Сформировать n_features новых признаков по формулам, приведённым выше.\n",
    "5. Обучить линейную модель (логистическую регрессию или SVM) на новых признаках.\n",
    "6. Повторить преобразования (PCA, формирование новых признаков) к тестовой выборке и применить модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_sGunb7K-hS"
   },
   "source": [
    "Тестировать алгоритм мы будем на данных Fashion MNIST. Ниже код для их загрузки и подготовки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "MAIN_SEED = 42\n",
    "\n",
    "rnd = np.random.default_rng(MAIN_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YyG6dBfjK-hS"
   },
   "outputs": [],
   "source": [
    "(x_train_pics, y_train), (x_test_pics, y_test) = fashion_mnist.load_data()\n",
    "x_train = x_train_pics.reshape(x_train_pics.shape[0], -1)\n",
    "x_test = x_test_pics.reshape(x_test_pics.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x_train / x_train.max()\n",
    "X_test = x_test / x_train.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJNN55F7K-hT"
   },
   "source": [
    "__Задание 1. (5 баллов)__\n",
    "\n",
    "Реализуйте алгоритм, описанный выше. Можете воспользоваться шаблоном класса ниже или написать свой интерфейс.\n",
    "\n",
    "Ваша реализация должна поддерживать следующие опции:\n",
    "1. Возможность задавать значения гиперпараметров new_dim (по умолчанию 50) и n_features (по умолчанию 1000).\n",
    "2. Возможность включать или выключать предварительное понижение размерности с помощью метода главных компонент.\n",
    "3. Возможность выбирать тип линейной модели (логистическая регрессия или SVM с линейным ядром).\n",
    "\n",
    "Протестируйте на данных Fashion MNIST, сформированных кодом выше. Если на тесте у вас получилась доля верных ответов не ниже 0.84 с гиперпараметрами по умолчанию, то вы всё сделали правильно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "jP8yepx8K-hT"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class RFFPipeline(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_features=1000, new_dim=50, use_PCA=True, classifier='logreg'):\n",
    "        \"\"\"        \n",
    "        Implements pipeline, which consists of PCA decomposition,\n",
    "        Random Fourier Features approximation and linear classification model.\n",
    "        \n",
    "        n_features, int: amount of synthetic random features generated with RFF approximation.\n",
    "\n",
    "        new_dim, int: PCA output size.ы\n",
    "        \n",
    "        use_PCA, bool: whether to include PCA preprocessing.\n",
    "        \n",
    "        classifier, string: either 'svm' or 'logreg', a linear classification model to use on top of pipeline.\n",
    "        \n",
    "        Feel free to edit this template for your preferences.    \n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        self.use_PCA = use_PCA\n",
    "        self.new_dim = new_dim\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit all parts of algorithm (PCA, RFF, Classification) to training set.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            self.pca= PCA(n_components=self.new_dim)\n",
    "            X = self.pca.fit_transform(X)\n",
    "\n",
    "        # Calculating sigma2\n",
    "\n",
    "        sigma_values = np.array([])\n",
    "\n",
    "        for _ in range(int(1e5)):\n",
    "            i, j = rnd.integers(X.shape[0], size=2)\n",
    "            if i == j:\n",
    "                i -= 1\n",
    "            sigma_values = np.append(sigma_values, np.sum((X[i] - X[j])) ** 2)\n",
    "        \n",
    "        sigma2 = sigma_values.mean()\n",
    "        #for _ in range(int(1e5)):\n",
    "        #    i, j = np.random.randint(0, len(X_train), size=2)\n",
    "        #    if i == j:\n",
    "        #        i = len(X_train) - i - 1\n",
    "        #        sigma_values = np.append(sigma_values, sum((X_train[i] - X_train[j]) ** 2))\n",
    "        #sigma2 = np.median(sigma_values)\n",
    "        \n",
    "\n",
    "        print(f'Sigma2 calculated {sigma2}')\n",
    "\n",
    "        # Calculating weights\n",
    "\n",
    "        self.w = rnd.normal(0, 1/np.sqrt(sigma2), (X.shape[1], self.n_features))\n",
    "        self.b = rnd.uniform(-np.pi, np.pi, self.n_features)\n",
    "\n",
    "        print('Weights calculated')\n",
    "\n",
    "        # Calculating phi matrix\n",
    "\n",
    "        phi_matrix = np.cos(X @ self.w + self.b)\n",
    "        print(phi_matrix.shape)\n",
    "\n",
    "        print('Phi matrix calculated')\n",
    "        \n",
    "        if self.classifier == 'svm':\n",
    "            self.class_ = SVC(kernel='linear')\n",
    "        elif self.classifier == 'logreg':\n",
    "            self.class_ = LogisticRegression()\n",
    "        \n",
    "        self.class_.fit(phi_matrix, y)\n",
    "        return self.w\n",
    "        \n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain scores for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "\n",
    "        phi_matrix = np.cos(X @ self.w + self.b)\n",
    "\n",
    "        return self.class_.predict_proba(phi_matrix)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Apply pipeline to obtain discrete predictions for input data.\n",
    "        \"\"\"\n",
    "        if self.use_PCA:\n",
    "            X = self.pca.transform(X)\n",
    "\n",
    "        phi_matrix = np.cos(X @ self.w + self.b)\n",
    "\n",
    "        return self.class_.predict(phi_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся сплитом, чтобы уменьшить выборку для обучения и при этом не потратить баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_kernel, _, y_train_kernel, _ = train_test_split(X_train, y_train, test_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma2 calculated 118.10371481760049\n",
      "Weights calculated\n",
      "(60000, 1000)\n",
      "Phi matrix calculated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fess/opt/anaconda3/envs/myenv/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.3 s, sys: 2.87 s, total: 1min\n",
      "Wall time: 25.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8564"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model = RFFPipeline()\n",
    "w = model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HYqQUEi-K-hU"
   },
   "source": [
    "__Задание 2. (3 балла)__\n",
    "\n",
    "Сравните подход со случайными признаками с обучением SVM на исходных признаках. Попробуйте вариант с обычным (линейным) SVM и с ядровым SVM. Ядровой SVM может очень долго обучаться, поэтому можно делать любые разумные вещи для ускорения: брать подмножество объектов из обучающей выборки, например.\n",
    "\n",
    "Сравните подход со случайными признаками с вариантом, в котором вы понижаете размерность с помощью PCA и обучаете градиентный бустинг. Используйте одну из реализаций CatBoost/LightGBM/XGBoost, не забудьте подобрать число деревьев и длину шага.\n",
    "\n",
    "Сделайте выводы — насколько идея со случайными признаками работает? Сравните как с точки зрения качества, так и с точки зрения скорости обучения и применения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "qN8LUlJgK-hV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8464"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "linear_SVM = SVC(kernel='linear')\n",
    "linear_SVM.fit(X_train, y_train)\n",
    "linear_predictions = linear_SVM.predict(X_test)\n",
    "accuracy_score(y_test, linear_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "kernel_SVM = SVC()\n",
    "kernel_SVM.fit(X_train_kernel, y_train_kernel)\n",
    "kernel_predictions = kernel_SVM.predict(X_test)\n",
    "accuracy_score(y_test, kernel_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=50)\n",
    "#X_train_boost = pca.fit_transform(X_train)\n",
    "#X_test_boost = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 20, 500),\n",
    "        'eta': trial.suggest_float('eta', 0, 1),\n",
    "        'silent': True,\n",
    "        'random_seed': MAIN_SEED,\n",
    "        'loss_function': 'MultiClass',\n",
    "        'task_type': 'GPU'\n",
    "    }\n",
    "\n",
    "    model = CatBoostClassifier(**params)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    result = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, result)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=MAIN_SEED)\n",
    "study = optuna.create_study(direction='minimize', sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\progress_bar.py:47: ExperimentalWarning: Progress bar is experimental (supported from v1.2.0). The interface can change in the future.\n",
      "  self._init_valid()\n",
      "100%|██████████| 100/100 [31:40<00:00, 19.00s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 183, 'eta': 0.00011823253634721254}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "best_boost = study.best_params\n",
    "best_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_boost = {\n",
    "    'random_seed': MAIN_SEED,\n",
    "    'loss_function': 'MultiClass',\n",
    "    'task_type': 'GPU'\n",
    "}\n",
    "\n",
    "for key in best_boost:\n",
    "    params_boost[key] = best_boost[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 183, 'eta': 0.00011823253634721254}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 2.3021000\ttotal: 45ms\tremaining: 8.18s\n",
      "1:\tlearn: 2.3015969\ttotal: 86.9ms\tremaining: 7.87s\n",
      "2:\tlearn: 2.3010922\ttotal: 129ms\tremaining: 7.71s\n",
      "3:\tlearn: 2.3005896\ttotal: 170ms\tremaining: 7.61s\n",
      "4:\tlearn: 2.3001005\ttotal: 212ms\tremaining: 7.56s\n",
      "5:\tlearn: 2.2995747\ttotal: 253ms\tremaining: 7.46s\n",
      "6:\tlearn: 2.2990628\ttotal: 297ms\tremaining: 7.46s\n",
      "7:\tlearn: 2.2985612\ttotal: 1.4s\tremaining: 30.6s\n",
      "8:\tlearn: 2.2980443\ttotal: 1.44s\tremaining: 27.9s\n",
      "9:\tlearn: 2.2975474\ttotal: 1.49s\tremaining: 25.7s\n",
      "10:\tlearn: 2.2970698\ttotal: 1.53s\tremaining: 23.9s\n",
      "11:\tlearn: 2.2965740\ttotal: 1.57s\tremaining: 22.4s\n",
      "12:\tlearn: 2.2960771\ttotal: 1.61s\tremaining: 21.1s\n",
      "13:\tlearn: 2.2955813\ttotal: 1.66s\tremaining: 20s\n",
      "14:\tlearn: 2.2950896\ttotal: 1.7s\tremaining: 19s\n",
      "15:\tlearn: 2.2945995\ttotal: 1.74s\tremaining: 18.2s\n",
      "16:\tlearn: 2.2941130\ttotal: 1.79s\tremaining: 17.4s\n",
      "17:\tlearn: 2.2936193\ttotal: 1.83s\tremaining: 16.8s\n",
      "18:\tlearn: 2.2931253\ttotal: 1.87s\tremaining: 16.2s\n",
      "19:\tlearn: 2.2926292\ttotal: 1.91s\tremaining: 15.6s\n",
      "20:\tlearn: 2.2921375\ttotal: 1.96s\tremaining: 15.1s\n",
      "21:\tlearn: 2.2916482\ttotal: 2s\tremaining: 14.6s\n",
      "22:\tlearn: 2.2911565\ttotal: 2.04s\tremaining: 14.2s\n",
      "23:\tlearn: 2.2906607\ttotal: 2.09s\tremaining: 13.8s\n",
      "24:\tlearn: 2.2901716\ttotal: 2.13s\tremaining: 13.5s\n",
      "25:\tlearn: 2.2896792\ttotal: 2.17s\tremaining: 13.1s\n",
      "26:\tlearn: 2.2891677\ttotal: 2.21s\tremaining: 12.8s\n",
      "27:\tlearn: 2.2886740\ttotal: 2.25s\tremaining: 12.5s\n",
      "28:\tlearn: 2.2881646\ttotal: 2.3s\tremaining: 12.2s\n",
      "29:\tlearn: 2.2876768\ttotal: 2.34s\tremaining: 11.9s\n",
      "30:\tlearn: 2.2871917\ttotal: 3.43s\tremaining: 16.8s\n",
      "31:\tlearn: 2.2867021\ttotal: 3.47s\tremaining: 16.4s\n",
      "32:\tlearn: 2.2862146\ttotal: 3.51s\tremaining: 15.9s\n",
      "33:\tlearn: 2.2857331\ttotal: 3.55s\tremaining: 15.6s\n",
      "34:\tlearn: 2.2852427\ttotal: 3.59s\tremaining: 15.2s\n",
      "35:\tlearn: 2.2847570\ttotal: 3.64s\tremaining: 14.8s\n",
      "36:\tlearn: 2.2842648\ttotal: 3.68s\tremaining: 14.5s\n",
      "37:\tlearn: 2.2837596\ttotal: 3.72s\tremaining: 14.2s\n",
      "38:\tlearn: 2.2832544\ttotal: 3.76s\tremaining: 13.9s\n",
      "39:\tlearn: 2.2827573\ttotal: 3.81s\tremaining: 13.6s\n",
      "40:\tlearn: 2.2822659\ttotal: 3.85s\tremaining: 13.3s\n",
      "41:\tlearn: 2.2817906\ttotal: 3.89s\tremaining: 13.1s\n",
      "42:\tlearn: 2.2813099\ttotal: 3.95s\tremaining: 12.9s\n",
      "43:\tlearn: 2.2808245\ttotal: 3.99s\tremaining: 12.6s\n",
      "44:\tlearn: 2.2803388\ttotal: 4.04s\tremaining: 12.4s\n",
      "45:\tlearn: 2.2798542\ttotal: 4.08s\tremaining: 12.2s\n",
      "46:\tlearn: 2.2793641\ttotal: 4.12s\tremaining: 11.9s\n",
      "47:\tlearn: 2.2788807\ttotal: 4.17s\tremaining: 11.7s\n",
      "48:\tlearn: 2.2783971\ttotal: 4.21s\tremaining: 11.5s\n",
      "49:\tlearn: 2.2779112\ttotal: 4.25s\tremaining: 11.3s\n",
      "50:\tlearn: 2.2774266\ttotal: 4.29s\tremaining: 11.1s\n",
      "51:\tlearn: 2.2769341\ttotal: 4.34s\tremaining: 10.9s\n",
      "52:\tlearn: 2.2764477\ttotal: 4.38s\tremaining: 10.7s\n",
      "53:\tlearn: 2.2759664\ttotal: 5.47s\tremaining: 13.1s\n",
      "54:\tlearn: 2.2754872\ttotal: 5.51s\tremaining: 12.8s\n",
      "55:\tlearn: 2.2749815\ttotal: 5.56s\tremaining: 12.6s\n",
      "56:\tlearn: 2.2745010\ttotal: 5.6s\tremaining: 12.4s\n",
      "57:\tlearn: 2.2740229\ttotal: 5.64s\tremaining: 12.2s\n",
      "58:\tlearn: 2.2735341\ttotal: 5.68s\tremaining: 11.9s\n",
      "59:\tlearn: 2.2730370\ttotal: 5.73s\tremaining: 11.7s\n",
      "60:\tlearn: 2.2725591\ttotal: 5.77s\tremaining: 11.5s\n",
      "61:\tlearn: 2.2720750\ttotal: 5.81s\tremaining: 11.3s\n",
      "62:\tlearn: 2.2715935\ttotal: 5.85s\tremaining: 11.2s\n",
      "63:\tlearn: 2.2711135\ttotal: 5.89s\tremaining: 11s\n",
      "64:\tlearn: 2.2706331\ttotal: 5.94s\tremaining: 10.8s\n",
      "65:\tlearn: 2.2701542\ttotal: 5.98s\tremaining: 10.6s\n",
      "66:\tlearn: 2.2696833\ttotal: 6.02s\tremaining: 10.4s\n",
      "67:\tlearn: 2.2691878\ttotal: 6.07s\tremaining: 10.3s\n",
      "68:\tlearn: 2.2687122\ttotal: 6.11s\tremaining: 10.1s\n",
      "69:\tlearn: 2.2682289\ttotal: 6.2s\tremaining: 10s\n",
      "70:\tlearn: 2.2677331\ttotal: 6.24s\tremaining: 9.84s\n",
      "71:\tlearn: 2.2672529\ttotal: 6.28s\tremaining: 9.68s\n",
      "72:\tlearn: 2.2667880\ttotal: 6.32s\tremaining: 9.52s\n",
      "73:\tlearn: 2.2663130\ttotal: 6.36s\tremaining: 9.37s\n",
      "74:\tlearn: 2.2658323\ttotal: 6.4s\tremaining: 9.22s\n",
      "75:\tlearn: 2.2653539\ttotal: 7.49s\tremaining: 10.5s\n",
      "76:\tlearn: 2.2648664\ttotal: 7.54s\tremaining: 10.4s\n",
      "77:\tlearn: 2.2643849\ttotal: 7.58s\tremaining: 10.2s\n",
      "78:\tlearn: 2.2638979\ttotal: 7.62s\tremaining: 10s\n",
      "79:\tlearn: 2.2634182\ttotal: 7.66s\tremaining: 9.86s\n",
      "80:\tlearn: 2.2629479\ttotal: 7.71s\tremaining: 9.7s\n",
      "81:\tlearn: 2.2624563\ttotal: 7.75s\tremaining: 9.54s\n",
      "82:\tlearn: 2.2619687\ttotal: 7.79s\tremaining: 9.38s\n",
      "83:\tlearn: 2.2615016\ttotal: 7.83s\tremaining: 9.23s\n",
      "84:\tlearn: 2.2610299\ttotal: 7.87s\tremaining: 9.08s\n",
      "85:\tlearn: 2.2605419\ttotal: 7.92s\tremaining: 8.93s\n",
      "86:\tlearn: 2.2600760\ttotal: 7.96s\tremaining: 8.78s\n",
      "87:\tlearn: 2.2596154\ttotal: 8s\tremaining: 8.64s\n",
      "88:\tlearn: 2.2591297\ttotal: 8.04s\tremaining: 8.49s\n",
      "89:\tlearn: 2.2586753\ttotal: 8.08s\tremaining: 8.35s\n",
      "90:\tlearn: 2.2581862\ttotal: 8.13s\tremaining: 8.21s\n",
      "91:\tlearn: 2.2577224\ttotal: 8.17s\tremaining: 8.08s\n",
      "92:\tlearn: 2.2572495\ttotal: 8.21s\tremaining: 7.95s\n",
      "93:\tlearn: 2.2567844\ttotal: 8.26s\tremaining: 7.82s\n",
      "94:\tlearn: 2.2563281\ttotal: 8.3s\tremaining: 7.69s\n",
      "95:\tlearn: 2.2558552\ttotal: 8.34s\tremaining: 7.56s\n",
      "96:\tlearn: 2.2554013\ttotal: 8.38s\tremaining: 7.43s\n",
      "97:\tlearn: 2.2549471\ttotal: 8.43s\tremaining: 7.31s\n",
      "98:\tlearn: 2.2544828\ttotal: 8.47s\tremaining: 7.18s\n",
      "99:\tlearn: 2.2540120\ttotal: 9.55s\tremaining: 7.92s\n",
      "100:\tlearn: 2.2535432\ttotal: 9.59s\tremaining: 7.79s\n",
      "101:\tlearn: 2.2530523\ttotal: 9.63s\tremaining: 7.65s\n",
      "102:\tlearn: 2.2525831\ttotal: 9.68s\tremaining: 7.52s\n",
      "103:\tlearn: 2.2520937\ttotal: 9.72s\tremaining: 7.38s\n",
      "104:\tlearn: 2.2516359\ttotal: 9.77s\tremaining: 7.25s\n",
      "105:\tlearn: 2.2511841\ttotal: 9.81s\tremaining: 7.12s\n",
      "106:\tlearn: 2.2507005\ttotal: 9.85s\tremaining: 7s\n",
      "107:\tlearn: 2.2502372\ttotal: 9.89s\tremaining: 6.87s\n",
      "108:\tlearn: 2.2497740\ttotal: 9.93s\tremaining: 6.74s\n",
      "109:\tlearn: 2.2493023\ttotal: 9.97s\tremaining: 6.62s\n",
      "110:\tlearn: 2.2488466\ttotal: 10s\tremaining: 6.5s\n",
      "111:\tlearn: 2.2483828\ttotal: 10.1s\tremaining: 6.38s\n",
      "112:\tlearn: 2.2479063\ttotal: 10.1s\tremaining: 6.25s\n",
      "113:\tlearn: 2.2474458\ttotal: 10.1s\tremaining: 6.14s\n",
      "114:\tlearn: 2.2469690\ttotal: 10.2s\tremaining: 6.02s\n",
      "115:\tlearn: 2.2465003\ttotal: 10.2s\tremaining: 5.91s\n",
      "116:\tlearn: 2.2460359\ttotal: 10.3s\tremaining: 5.79s\n",
      "117:\tlearn: 2.2455773\ttotal: 10.3s\tremaining: 5.68s\n",
      "118:\tlearn: 2.2451133\ttotal: 10.4s\tremaining: 5.57s\n",
      "119:\tlearn: 2.2446437\ttotal: 10.4s\tremaining: 5.46s\n",
      "120:\tlearn: 2.2441828\ttotal: 10.4s\tremaining: 5.35s\n",
      "121:\tlearn: 2.2437414\ttotal: 10.5s\tremaining: 5.24s\n",
      "122:\tlearn: 2.2432935\ttotal: 11.6s\tremaining: 5.64s\n",
      "123:\tlearn: 2.2428286\ttotal: 11.6s\tremaining: 5.52s\n",
      "124:\tlearn: 2.2423617\ttotal: 11.6s\tremaining: 5.41s\n",
      "125:\tlearn: 2.2419120\ttotal: 11.7s\tremaining: 5.29s\n",
      "126:\tlearn: 2.2414430\ttotal: 11.7s\tremaining: 5.17s\n",
      "127:\tlearn: 2.2409846\ttotal: 11.8s\tremaining: 5.06s\n",
      "128:\tlearn: 2.2405307\ttotal: 11.8s\tremaining: 4.95s\n",
      "129:\tlearn: 2.2400745\ttotal: 11.9s\tremaining: 4.84s\n",
      "130:\tlearn: 2.2396229\ttotal: 11.9s\tremaining: 4.72s\n",
      "131:\tlearn: 2.2391727\ttotal: 11.9s\tremaining: 4.62s\n",
      "132:\tlearn: 2.2387148\ttotal: 12s\tremaining: 4.51s\n",
      "133:\tlearn: 2.2382656\ttotal: 12s\tremaining: 4.4s\n",
      "134:\tlearn: 2.2378104\ttotal: 12.1s\tremaining: 4.29s\n",
      "135:\tlearn: 2.2373589\ttotal: 12.1s\tremaining: 4.19s\n",
      "136:\tlearn: 2.2368865\ttotal: 12.2s\tremaining: 4.08s\n",
      "137:\tlearn: 2.2364279\ttotal: 12.2s\tremaining: 3.98s\n",
      "138:\tlearn: 2.2359753\ttotal: 12.2s\tremaining: 3.88s\n",
      "139:\tlearn: 2.2355224\ttotal: 12.3s\tremaining: 3.77s\n",
      "140:\tlearn: 2.2350680\ttotal: 12.3s\tremaining: 3.67s\n",
      "141:\tlearn: 2.2346089\ttotal: 12.4s\tremaining: 3.57s\n",
      "142:\tlearn: 2.2341526\ttotal: 12.4s\tremaining: 3.47s\n",
      "143:\tlearn: 2.2336797\ttotal: 12.5s\tremaining: 3.37s\n",
      "144:\tlearn: 2.2332099\ttotal: 12.5s\tremaining: 3.27s\n",
      "145:\tlearn: 2.2327531\ttotal: 12.5s\tremaining: 3.18s\n",
      "146:\tlearn: 2.2323010\ttotal: 13.6s\tremaining: 3.34s\n",
      "147:\tlearn: 2.2318529\ttotal: 13.7s\tremaining: 3.23s\n",
      "148:\tlearn: 2.2314036\ttotal: 13.7s\tremaining: 3.13s\n",
      "149:\tlearn: 2.2309424\ttotal: 13.8s\tremaining: 3.03s\n",
      "150:\tlearn: 2.2304857\ttotal: 13.8s\tremaining: 2.92s\n",
      "151:\tlearn: 2.2300268\ttotal: 13.8s\tremaining: 2.82s\n",
      "152:\tlearn: 2.2295786\ttotal: 13.9s\tremaining: 2.72s\n",
      "153:\tlearn: 2.2291310\ttotal: 14s\tremaining: 2.63s\n",
      "154:\tlearn: 2.2286711\ttotal: 14s\tremaining: 2.53s\n",
      "155:\tlearn: 2.2282240\ttotal: 14s\tremaining: 2.43s\n",
      "156:\tlearn: 2.2277846\ttotal: 14.1s\tremaining: 2.33s\n",
      "157:\tlearn: 2.2273310\ttotal: 14.1s\tremaining: 2.23s\n",
      "158:\tlearn: 2.2268768\ttotal: 14.2s\tremaining: 2.14s\n",
      "159:\tlearn: 2.2264276\ttotal: 14.2s\tremaining: 2.04s\n",
      "160:\tlearn: 2.2259771\ttotal: 14.2s\tremaining: 1.95s\n",
      "161:\tlearn: 2.2255315\ttotal: 14.3s\tremaining: 1.85s\n",
      "162:\tlearn: 2.2250891\ttotal: 14.3s\tremaining: 1.76s\n",
      "163:\tlearn: 2.2246375\ttotal: 14.4s\tremaining: 1.66s\n",
      "164:\tlearn: 2.2241935\ttotal: 14.4s\tremaining: 1.57s\n",
      "165:\tlearn: 2.2237461\ttotal: 14.5s\tremaining: 1.48s\n",
      "166:\tlearn: 2.2233034\ttotal: 14.5s\tremaining: 1.39s\n",
      "167:\tlearn: 2.2228576\ttotal: 14.5s\tremaining: 1.3s\n",
      "168:\tlearn: 2.2224068\ttotal: 14.6s\tremaining: 1.21s\n",
      "169:\tlearn: 2.2219487\ttotal: 15.7s\tremaining: 1.2s\n",
      "170:\tlearn: 2.2214909\ttotal: 15.7s\tremaining: 1.1s\n",
      "171:\tlearn: 2.2210294\ttotal: 15.8s\tremaining: 1.01s\n",
      "172:\tlearn: 2.2205875\ttotal: 15.8s\tremaining: 913ms\n",
      "173:\tlearn: 2.2201263\ttotal: 15.8s\tremaining: 819ms\n",
      "174:\tlearn: 2.2196815\ttotal: 15.9s\tremaining: 726ms\n",
      "175:\tlearn: 2.2192341\ttotal: 15.9s\tremaining: 633ms\n",
      "176:\tlearn: 2.2187690\ttotal: 16s\tremaining: 541ms\n",
      "177:\tlearn: 2.2183164\ttotal: 16s\tremaining: 450ms\n",
      "178:\tlearn: 2.2178865\ttotal: 16.1s\tremaining: 359ms\n",
      "179:\tlearn: 2.2174424\ttotal: 16.1s\tremaining: 268ms\n",
      "180:\tlearn: 2.2169979\ttotal: 16.1s\tremaining: 178ms\n",
      "181:\tlearn: 2.2165549\ttotal: 16.2s\tremaining: 88.9ms\n",
      "182:\tlearn: 2.2161052\ttotal: 16.2s\tremaining: 0us\n",
      "Wall time: 26.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7027"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "boost_model = CatBoostClassifier(**params_boost)\n",
    "boost_model.fit(X_train, y_train)\n",
    "boost_predictions = boost_model.predict(X_test)\n",
    "accuracy_score(y_test, boost_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6umjhWuK-hV"
   },
   "source": [
    "__Задание 3. (2 балла)__\n",
    "\n",
    "Проведите эксперименты:\n",
    "1. Помогает ли предварительное понижение размерности с помощью PCA? \n",
    "2. Как зависит итоговое качество от n_features? Выходит ли оно на плато при росте n_features?\n",
    "3. Важно ли, какую модель обучать — логистическую регрессию или SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2QIHIMbK-hW"
   },
   "outputs": [],
   "source": [
    "result = {}\n",
    "for model in ['logreg', 'svm']:\n",
    "    result_acc = []\n",
    "    for n_features in [100, 300, 500, 700, 1000, 1500, 2000, 5000]:\n",
    "        model = RFFPipeline()\n",
    "        result_acc.appe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CJqXVuasK-hW"
   },
   "source": [
    "### Бонус"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVDWHCdrK-hX"
   },
   "source": [
    "__Задание 4. (Максимум 2 балла)__\n",
    "\n",
    "Как вы, должно быть, помните с курса МО-1, многие алгоритмы машинного обучения работают лучше, если признаки данных некоррелированы. Оказывается, что для RFF существует модификация, позволяющая получать ортогональные случайные признаки (Orthogonal Random Features, ORF). Об этом методе можно прочитать в [статье](https://proceedings.neurips.cc/paper/2016/file/53adaf494dc89ef7196d73636eb2451b-Paper.pdf). Реализуйте класс для вычисления ORF по аналогии с основным заданием. Обратите внимание, что ваш класс должен уметь работать со случаем n_features > new_dim (в статье есть замечание на этот счет). Проведите эксперименты, сравнивающие RFF и ORF, сделайте выводы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSxvGI9iK-hX"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pc7-1jmK-hY"
   },
   "source": [
    "__Задание 5. (Максимум 2 балла)__\n",
    "\n",
    "Поэкспериментируйте с функциями для вычисления новых случайных признаков. Не обязательно использовать косинус от скалярного произведения — можно брать знак от него, хэш и т.д. Придумайте побольше вариантов для генерации признаков и проверьте, не получается ли с их помощью добиваться более высокого качества. Также можете попробовать другой классификатор поверх случайных признаков, сравните результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dWj-O2vjK-hY"
   },
   "outputs": [],
   "source": [
    "# Your code here: (￣▽￣)/♫•*¨*•.¸¸♪"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "homework-practice-08-random-features.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
